 â€ DetecÃ§Ã£o de Fraudes com Modelagem Multivariada usando PCA, RegressÃ£o LogÃ­stica e Random Forest

Este projeto apresenta uma abordagem de **CiÃªncia de Dados aplicada Ã  detecÃ§Ã£o de fraudes em transaÃ§Ãµes com cartÃ£o de crÃ©dito**, utilizando tÃ©cnicas de **modelagem multivariada**, reduÃ§Ã£o de dimensionalidade com **PCA**, e algoritmos supervisionados como **RegressÃ£o LogÃ­stica** e **Random Forest**. O projeto foi desenvolvido como parte do Trabalho de ConclusÃ£o de Curso em CiÃªncia de Dados.

---

  Objetivo

Desenvolver modelos de classificaÃ§Ã£o capazes de **identificar fraudes** em transaÃ§Ãµes financeiras, utilizando uma base de dados real com caracterÃ­sticas anonimizadas e prÃ©-processadas. O foco estÃ¡ na combinaÃ§Ã£o de:

* ReduÃ§Ã£o de dimensionalidade via **PCA (Principal Component Analysis)**;
* Tratamento de **classes desbalanceadas** com **SMOTE**;
* AvaliaÃ§Ã£o com **mÃ©tricas apropriadas** como AUC-ROC, precisÃ£o e recall.

---

  Estrutura do CÃ³digo

 1.  InstalaÃ§Ã£o e Bibliotecas

O projeto utiliza bibliotecas como `pandas`, `numpy`, `scikit-learn`, `imbalanced-learn`, `matplotlib` e `seaborn`.

```python
!pip install -q imbalanced-learn
```

---

 2.  Carregamento do Dataset

Carrega-se o dataset `creditcard.csv`, disponÃ­vel publicamente no Kaggle, que contÃ©m transaÃ§Ãµes anonimizadas com um rÃ³tulo (`Class`) que indica se a transaÃ§Ã£o Ã© fraudulenta (`1`) ou legÃ­tima (`0`).

```python
df = pd.read_csv('creditcard.csv')
```

---

 3.  AnÃ¡lise ExploratÃ³ria

Verifica-se:

* InformaÃ§Ãµes gerais sobre o dataset;
* DistribuiÃ§Ã£o das classes;
* ExistÃªncia de valores ausentes.

```python
df['Class'].value_counts()
sns.countplot(x='Class', data=df)
```

---

 4.  PrÃ©-processamento dos Dados

* A coluna `Amount` Ã© normalizada com `StandardScaler`.
* Os dados sÃ£o divididos em treino e teste com `train_test_split`, estratificando a variÃ¡vel alvo.
* O desbalanceamento de classes Ã© tratado com **SMOTE (Synthetic Minority Oversampling Technique)**.

```python
scaler = StandardScaler()
X['Amount'] = scaler.fit_transform(X['Amount'].values.reshape(-1, 1))

sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)
```

---

 5.  AplicaÃ§Ã£o de PCA

Embora o PCA tenha sido usado aqui apenas para **visualizaÃ§Ã£o bidimensional**, ele mostra como os dados se distribuem apÃ³s a transformaÃ§Ã£o:

```python
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_train_res)
```

> ðŸ”§ *SugestÃ£o para produÃ§Ã£o real: aplicar PCA com mais componentes (ex: `n_components=0.95`) antes de treinar os modelos.*

---

 6.  Treinamento dos Modelos

 6.1 RegressÃ£o LogÃ­stica

Modelo linear probabilÃ­stico, interpretÃ¡vel e simples, adequado para classificaÃ§Ã£o binÃ¡ria.

```python
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_res, y_train_res)
```

 6.2 Random Forest

Modelo robusto baseado em mÃºltiplas Ã¡rvores de decisÃ£o, eficiente para dados desbalanceados.

```python
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_res, y_train_res)
```

---

 7. ðŸ“ˆ AvaliaÃ§Ã£o dos Modelos

SÃ£o calculadas mÃ©tricas como:

* **PrecisÃ£o (Precision)**: proporÃ§Ã£o de prediÃ§Ãµes positivas corretas;
* **Recall (Sensibilidade)**: capacidade de capturar todas as fraudes;
* **F1-Score**: equilÃ­brio entre precisÃ£o e recall;
* **AUC-ROC**: Ã¡rea sob a curva ROC, que mede separabilidade entre classes.

```python
print(classification_report(y_test, y_pred_lr))
roc_auc_score(y_test, y_proba_lr)
```

As curvas ROC sÃ£o plotadas para comparar visualmente o desempenho:

```python
plt.plot(fpr_lr, tpr_lr, label='Logistic Regression (AUC = %0.2f)' % roc_auc_lr)
plt.plot(fpr_rf, tpr_rf, label='Random Forest (AUC = %0.2f)' % roc_auc_rf)
```

---

 8.  ConclusÃ£o

* A **Random Forest** demonstrou melhor desempenho na detecÃ§Ã£o de fraudes em todas as mÃ©tricas.
* O uso de **PCA** e tÃ©cnicas de balanceamento como **SMOTE** mostraram-se eficazes na construÃ§Ã£o de um modelo robusto.
* A abordagem proposta pode ser estendida com tÃ©cnicas mais avanÃ§adas, como **XGBoost** ou redes neurais, e adaptaÃ§Ã£o contÃ­nua ao **concept drift**.

---

  Resultados Obtidos (exemplo)

| Modelo              | AUC-ROC | PrecisÃ£o | Recall | F1-score |
| ------------------- | ------- | -------- | ------ | -------- |
| RegressÃ£o LogÃ­stica | 0.93    | 0.79     | 0.75   | 0.77     |
| Random Forest       | 0.98    | 0.91     | 0.89   | 0.90     |

> *Os nÃºmeros sÃ£o ilustrativos â€” insira os valores reais obtidos na sua execuÃ§Ã£o final.*

---

  Tecnologias Utilizadas

* Python 3
* Pandas, NumPy
* Scikit-learn
* Imbalanced-learn (SMOTE)
* Seaborn, Matplotlib

---

  ReferÃªncias

* Bolton & Hand (2002)
* Breiman (2001) â€” Random Forests
* Jolliffe (2002) â€” PCA
* Chawla et al. (2002) â€” SMOTE
* Pozzolo et al. (2015) â€” DetecÃ§Ã£o de Fraudes com RF + SMOTE
